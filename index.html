<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GNF: Gaussian Neural Fields for Multidimensional Signal Representation and Reconstruction</title>
    <meta name="description" content="We've presented GNF, a fast and compact framework for neural fields representation.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <!-- <meta content="website" property="og:type"> -->
    <!-- <meta content="https://shikun.io/projects/clarity" property="og:url"> -->
    <meta content="GNF" property="og:title">
    <meta content="Gaussian Neural Fields for Multidimensional Signal Representation and Reconstruction" property="og:description">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@your_twitter_id">
    <meta name="twitter:description" content="GNF: Gaussian Neural Fields for Multidimensional Signal Representation and Reconstruction">
    <!-- <meta name="twitter:image:src" content="assets/figures/clarity.png"> -->

    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/PLYLoader.js"></script>
    <script src="assets/scripts/mesh-viewer.js"></script>
    <script src="assets/scripts/navbar.js"></script> <!-- Comment to remove table of content. -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <style>
        .mesh-viewer-container {
            position: relative;
        }
        .interaction-hint {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 40px;
            height: 40px;
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top-color: rgba(255, 255, 255, 0.8);
            animation: spin 1s linear infinite, fadeOut 3s forwards;
            pointer-events: none;
            z-index: 1000;
        }
        @keyframes spin {
            to { transform: translate(-50%, -50%) rotate(360deg); }
        }
        @keyframes fadeOut {
            0% { opacity: 1; }
            70% { opacity: 1; }
            100% { opacity: 0; }
        }
    </style>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background-color: #E0E4E6;">
        <!-- If you don't have a project cover: Change "blog-title" into "blog-title no-cover"  -->
     
            <div class="blog-intro no-cover">
                <div>
                    <h1 class="title">GNF: Gaussian Neural Fields for Multidimensional Signal Representation and Reconstruction</h1>
                        <div>

                        </div>
                    <p class="author">Anonymous Author(s)</p>
                    <div>
                        <br>
                    </div>

                    <p class="abstract">
                        We introduce GNF, a novel framework that leverages Gaussian Radial basis Functions to represent neural fields efficiently. We demonstrate its effectiveness in representing 3D geometry, RGB images, and radiance fields.                    </p>
                   
                </div>
                <h1>
                    
                </h1>
                
                <div class="info">
                    <div>
                        <a href="https://anonymous.4open.science/r/GRBFNet" class="button icon" style="background-color: rgba(255, 255, 255, 0.25); margin-bottom: 0;">Source Code <i class="fa-solid fa-code"></i></a>
                        <a href="" class="button icon" style="background-color: rgba(255, 255, 255, 0.25); margin-bottom: 0;"> Paper <i class="fa-solid fa-sheet-plastic"></i></a>
                    </div>
                    
            </div>

            <!-- <div class="blog-cover">
                <img class="foreground" src="assets/figures/clarity.png">
                <img class="background" src="assets/figures/clarity.png">
            </div> -->
        </div>
    </div>

    <div class="container blog" style="background-color: #ffffff;">
        <div style="width: 100%; display: flex; justify-content: center;">
            <img src="assets/figures/cover.png" alt="GNF Model Overview" style="width: 100%; height: auto; display: block; margin: 0;">
        </div>
    </div>

    <div class="container blog main first" id="blog-main">
        <h1>
            Introduction
        </h1>
        <p class='text'>
            In this paper, we introduce Gaussian Neural Fields (GNF), a novel lightweight decoder based on Radial Basis Functions (RBFs). Instead of using traditional MLPs—which approximate nonlinear functions via piecewise linear activations (e.g. ReLU)—our method leverages smooth Gaussian kernels defined directly in the learned feature space. Each radial unit computes its activation from the Euclidean distance between the input feature and a learned center, with per-dimension scaling enabling anisotropic and localized modeling in feature space.  
            By aligning kernel dimensionality with the learned input features, GNF effectively represents highly nonlinear signals with a single decoding layer consisting of fewer than 64 units—significantly more compact than shallow three-layer MLPs used in state-of-the-art methods. This minimal architectural depth shortens gradient paths, accelerating training and inference. Additionally, our fully vectorized implementation reduces computational complexity from O(BN²) to O(BN), where B is the batch size and N is the number of decoding units. As a result, GNF achieves comparable reconstruction quality using only about 78% of the floating-point operations (FLOPs) required by a three-layer MLP.
        </p>

    </div>


    <div class="container blog main white ">
            <img src="assets/figures/fig-1.png">
            <p class="caption">
                Our model (third figure from the left) stands out with its single decoding layer compared to other neural field models.
            </p>
        </div>
    </div>



   
    <div class="container blog main gray">
        <h1>
            SDF representation
        </h1>
        <h2>
            Comparison with DiF-Grid
        </h2>
        <p class='text'>
            The meshes below show the zero-level sets of the Signed Distance Function (SDF) estimated by our model and the DiF-Grid model from FactorFields <a href="#ref1">[1]</a>.
            Our model uses approximately 3.5 million parameters and converges in 15 seconds, compared to 5 million parameters and 20 seconds for DiF-Grid <a href="#ref1">[1]</a>. While both models produce comparable results, ours captures finer scene details with fewer parameters and faster convergence.
            For each shape, corresponding views are aligned to allow a direct comparison.
        </p>
    </div>

    <div class="container blog main white">
        <div id="synced-mesh-viewers" style="width: 100%; display: flex; justify-content: center;">
            <div class="interaction-hint"></div>
        </div>
        <script src="assets/scripts/mesh-viewer-sbs.js"></script>
        <script>
            new SyncedMeshViewers(
                'synced-mesh-viewers',
                {
                    gltfPath: 'assets/figures/meshes/xyzrgb_statuette.gltf',
                    title: 'DiF-Grid [1]'
                },
                {
                    gltfPath: 'assets/figures/meshes/output.gltf',
                    title: 'GNF (Ours)'
                },
                {
                    initialRotation: {x: Math.PI/2, y: 0, z: 0},
                    initialZoom: 2.8,
                    rotationAxis: {x: 0, y: 0, z: 1},
                    lightIntensity: 0.6,
                    autoRotate: true,
                    autoRotateSpeed: 0.5,
                    breathingAnimation: {
                        enabled: true,
                        scale: 1.05,
                        duration: 2,
                        stopOnInteraction: true
                    }
                }
            );
        </script>
        <div id="synced-mesh-viewers-2" style="width: 100%; display: flex; justify-content: center; margin-top: 48px;">
            <div class="interaction-hint"></div>
        </div>
        <script>
            new SyncedMeshViewers(
                'synced-mesh-viewers-2',
                {
                    gltfPath: 'assets/figures/meshes/lucy.gltf',
                    title: 'DiF-Grid'
                },
                {
                    gltfPath: 'assets/figures/meshes/output_lucy.gltf',
                    title: 'GNF (Ours)'
                },
                {
                    initialRotation: {x: 0, y: Math.PI/2, z: 0},
                    initialZoom: 2.8,
                    rotationAxis: {x: 0, y: 1, z: 0},
                    lightIntensity: 0.8,
                    autoRotate: true,
                    autoRotateSpeed: 0.5,
                    breathingAnimation: {
                        enabled: true,
                        scale: 1.05,
                        duration: 2,
                        stopOnInteraction: true
                    }
                }
            );
        </script>

        <div id="synced-mesh-viewers-3" style="width: 100%; display: flex; justify-content: center; margin-top: 48px;">
            <div class="interaction-hint"></div>
        </div>
        <script>
            new SyncedMeshViewers(
                'synced-mesh-viewers-3',
                {
                    gltfPath: 'assets/figures/meshes/xyzrgb_dragon.ply.glb',
                    title: 'DiF-Grid'
                },
                {
                    gltfPath: 'assets/figures/meshes/output_dragon.ply.glb',
                    title: 'GNF (Ours)'
                },
                {
                    initialRotation: {x: 0, y: Math.PI/2, z: 0},
                    initialZoom: 2.8,
                    rotationAxis: {x: 0, y: 1, z: 0},
                    lightIntensity: 1,
                    autoRotate: true,
                    autoRotateSpeed: 0.5,
                    breathingAnimation: {
                        enabled: true,
                        scale: 1.05,
                        duration: 2,
                        stopOnInteraction: true
                    }
                }
            );
        </script>
        <h2>
            Comparison with NeuRBF
        </h2>
        <p class='text'>
            The meshes below show the zero-level sets of the Signed Distance Function (SDF) estimated by our model and the NeuRBF model <a href="#ref2">[2]</a>.
            Our model converges in 15 seconds, compared to 60 seconds for NeuRBF <a href="#ref2">[2]</a>. While both models produce comparable results.
            For each shape, corresponding views are aligned to allow a direct comparison.
        </p>
    </div>

    <div class="container blog main white">
        <div id="synced-mesh-viewers-neurbf" style="width: 100%; display: flex; justify-content: center;">
            <div class="interaction-hint"></div>
        </div>
        <script>
            new SyncedMeshViewers(
                'synced-mesh-viewers-neurbf',
                {
                    gltfPath: 'assets/figures/meshes/Armadillo_nrml-neurbf-v0.ply.glb',
                    title: 'NeuRBF'
                },
                {
                    gltfPath: 'assets/figures/meshes/Armadillo_nrml-ours.ply.glb',
                    title: 'GNF (Ours)'
                },
                {
                    initialRotation: {x: 0, y: 0, z: 0},
                    // initialRotation: {x: -Math.PI/2, y: 0, z: -Math.PI/2},
                    initialZoom: 2.8,
                    rotationAxis: {x: 0, y: 1, z: 0},
                    lightIntensity: 1,
                    autoRotate: true,
                    autoRotateSpeed: 0.5,
                    breathingAnimation: {
                        enabled: true,
                        scale: 1.05,
                        duration: 2,
                        stopOnInteraction: true
                    }
                }
            );
        </script>
        <div id="synced-mesh-viewers-neurbf-2" style="width: 100%; display: flex; justify-content: center; margin-top: 48px;">
            <div class="interaction-hint"></div>
        </div>
        <script>
            new SyncedMeshViewers(
                'synced-mesh-viewers-neurbf-2',
                {
                    gltfPath: 'assets/figures/meshes/buddhaPNG_Mesh_TIP19Li_neurbf.ply.glb',
                    title: 'NeuRBF'
                },
                {
                    gltfPath: 'assets/figures/meshes/buddhaPNG_Mesh_TIP19Li_ours.glb',
                    title: 'GNF (Ours)'
                },
                {
                    initialRotation: {x: -Math.PI/2, y: 0, z: Math.PI/2},
                    initialZoom: 2.8,
                    rotationAxis: {x: 0, y: 0, z: 1},
                    lightIntensity: 1,
                    autoRotate: true,
                    autoRotateSpeed: 0.5,
                    breathingAnimation: {
                        enabled: true,
                        scale: 1.05,
                        duration: 2,
                        stopOnInteraction: true
                    }
                }
            );
        </script>
        <div id="synced-mesh-viewers-neurbf-3" style="width: 100%; display: flex; justify-content: center; margin-top: 48px;">
            <div class="interaction-hint"></div>
        </div>
        <script>
            new SyncedMeshViewers(
                'synced-mesh-viewers-neurbf-3',
                {
                    gltfPath: 'assets/figures/meshes/happy_vrip_nrml-neurbf.ply.glb',
                    title: 'NeuRBF'
                },
                {
                    gltfPath: 'assets/figures/meshes/happy_vrip_nrml-ours.ply.glb',
                    title: 'GNF (Ours)'
                },
                {
                    initialRotation: {x: 0, y: Math.PI/2, z: 0},
                    initialZoom: 2.8,
                    rotationAxis: {x: 0, y: 1, z: 0},
                    lightIntensity: 1,
                    autoRotate: true,
                    autoRotateSpeed: 0.5,
                    breathingAnimation: {
                        enabled: true,
                        scale: 1.05,
                        duration: 2,
                        stopOnInteraction: true
                    }
                }
            );
        </script>
    </div>

    <div class="container blog main first" id="blog-main">
        <h1>
            Ultra-Fast Convergence!
        </h1>
        <p class='text'>
            The video below presents the extracted mesh during our model's training, with the training timer displayed in the bottom-left corner.
        </p>
        <video id="video3" loop playsinline muted autoplay src="clarity/videos/output_video.mp4" style="width: 100%"> </video>
        <p class="caption">
            The overall shape is captured within a few seconds.
        </p>
    </div>



    <div class="container blog main first" id="blog-main">
        <h1>
            Image representation
        </h1>
        <p class='text'>
            We use our model with a single RBF layer to fit high-resolution images. See examples below. 
        </p>

    </div>

    <div class="container blog main gray">
        <div class="slide-menu">
            <ul class="dots" id="slide-menu">
                <li class="dot active"></li>
                <li class="dot"></li>
                <li class="dot"></li>
                <li class="dot"></li>
            </ul>
        </div>
        <div class="slide-content" style="display: block; position: relative;">
            <a class="button icon" id="img_prev_btn" style="position: absolute; left: 0; top: 50%; transform: translateY(-50%); z-index: 2;"><i class="fa-solid fa-arrow-left"></i></a>
            <video id="video2" loop playsinline muted autoplay src="clarity/videos/pluto.mp4" style="width: 75%"></video>
            <a class="button icon" id="img_next_btn" style="position: absolute; right: 0; top: 50%; transform: translateY(-50%); z-index: 2;"><i class="fa-solid fa-arrow-right"></i></a>
        </div>
        <div class="slide-content" style="display: none; position: relative;">
            <a class="button icon" id="img_prev_btn2" style="position: absolute; left: 0; top: 50%; transform: translateY(-50%); z-index: 2;"><i class="fa-solid fa-arrow-left"></i></a>
            <video id="video1" loop playsinline muted autoplay src="clarity/videos/girl.mp4" style="width: 75%"></video>
            <a class="button icon" id="img_next_btn2" style="position: absolute; right: 0; top: 50%; transform: translateY(-50%); z-index: 2;"><i class="fa-solid fa-arrow-right"></i></a>
        </div>
        <div class="slide-content" style="display: none; position: relative;">
            <a class="button icon" id="img_prev_btn3" style="position: absolute; left: 0; top: 50%; transform: translateY(-50%); z-index: 2;"><i class="fa-solid fa-arrow-left"></i></a>
            <video id="video_shibuya" loop playsinline muted autoplay src="clarity/videos/shibuya.mp4" style="width: 75%"></video>
            <a class="button icon" id="img_next_btn3" style="position: absolute; right: 0; top: 50%; transform: translateY(-50%); z-index: 2;"><i class="fa-solid fa-arrow-right"></i></a>
        </div>
        <div class="slide-content" style="display: none; position: relative;">
            <a class="button icon" id="img_prev_btn4" style="position: absolute; left: 0; top: 50%; transform: translateY(-50%); z-index: 2;"><i class="fa-solid fa-arrow-left"></i></a>
            <video id="video5" loop playsinline muted autoplay src="clarity/videos/weiss.mp4" style="width: 75%"></video>
            <a class="button icon" id="img_next_btn4" style="position: absolute; right: 0; top: 50%; transform: translateY(-50%); z-index: 2;"><i class="fa-solid fa-arrow-right"></i></a>
        </div>
        <p class="caption">
            Zoom-in visualization of reconstructed images generated by our model.
        </p>
    </div>

    <div class="container blog main first" id="blog-main">
        <h1>
            Radiance fields representation
        </h1>
        <p class='text'>
            We extend our framework to support a higher number of outputs, enabling the estimation of spherical harmonics for novel view generation. The proposed GNF-SH model architecture is illustrated in the figure below.
        </p>

    </div>
    <div class="container blog main white">
            <img src="assets/figures/Gaussian RBF-SH.jpg">
            <p class="caption">
                Network architecture of the radiance fields model.
            </p>
        </div>
    </div>




  
    <div class="container blog main white">
        <div class="slideshow">
            <div class="navigation">
                <!-- Using FontAwesome Pro -->
                <!-- <a class="button icon" id="prev_btn"><i class="fa-solid fa-left" ></i></a>
                <a class="button icon" id="next_btn"><i class="fa-solid fa-right"></i></a> -->
                <!-- Using FontAwesome Free -->
                <a class="button icon" id="prev_btn"><i class="fa-solid fa-arrow-left"></i></a>
                <a class="button icon" id="next_btn"><i class="fa-solid fa-arrow-right"></i></a>
            </div>
            <div class="slider">
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="clarity/videos/chair.mp4"></video>
                </div>
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="clarity/videos/mic.mp4"></video>
                </div>
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="clarity/videos/ship.mp4"></video>
                </div>
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="clarity/videos/ficus.mp4"></video>
                </div>
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="clarity/videos/lego.mp4"></video>
                </div>
            </div>
            <p class="caption">
                Novel views generated with our model.
            </p>
        </div>
    </div>

    

    <div class="container blog main gray">
        <div class="slide-menu">
            <ul class="dots" id="slide-menu">

            </ul>
        </div>
       
    </div>

    <div class="container blog main gray">
        <h1>
            References
        </h1>
        <div style="margin-bottom: 1em;">
          <b>[1] Factor Fields:</b><br>
          <span style="font-style: italic;">
            Chen, A., Xu, Z., Wei, X., Tang, S., Su, H., & Geiger, A. (2023).
            <a href="https://arxiv.org/abs/2302.01226" target="_blank" rel="noopener">
              Factor Fields: A Unified Framework for Neural Fields and Beyond
            </a>.
            arXiv preprint arXiv:2302.01226.
          </span>
        </div>
        <div style="margin-bottom: 1em;">
          <b>[2] NeuRBF:</b><br>
          <span style="font-style: italic;">
            Chen, Z., Li, Z., Song, L., Chen, L., Yu, J., Yuan, J., & Xu, Y. (2023).
            <a href="https://arxiv.org/abs/2309.15426" target="_blank" rel="noopener">
              NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions
            </a>.
            In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 4182-4194).
          </span>
        </div>
    </div>

    <div style="
        width: 100%;
        background: #E0E4E6;
        padding: 24px 0 12px 0;
        text-align: center;
        font-family: 'Poppins', 'Brush Script MT', cursive, sans-serif;
        font-size: 1.1em;
        letter-spacing: 0.5px;
        color: #353535;
        margin-top: 40px;
        border-top: 0px solid #eee;
    ">
        <span style="font-style: italic; display: inline-block;">
            <i class="fa-solid fa-paintbrush" style="color:#E2a3a3; margin-right: 8px;"></i>
            Adapted from <a href="https://github.com/lorenmt/clarity-template" target="_blank" rel="noopener" style="color:#353535; text-decoration: underline dotted;">Clarity Template</a> by @lorenmt
        </span>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    <script>
        // Function to pause and restart video with delay
        function addPauseBeforeReplay(videoElement, pauseDuration) {
            if (!videoElement) return; // Prevents error if element doesn't exist
            videoElement.removeAttribute('loop');  // Disable loop to control manually
    
            videoElement.addEventListener('ended', function () {
                setTimeout(() => {
                    videoElement.currentTime = 0;  // Reset video to start
                    videoElement.play();
                }, pauseDuration);
            });
        }
    
        // Apply to both videos with a 2-second delay (2000 milliseconds)
        document.addEventListener('DOMContentLoaded', () => {
            addPauseBeforeReplay(document.getElementById('video1'), 2000);
            addPauseBeforeReplay(document.getElementById('video2'), 2000);
            addPauseBeforeReplay(document.getElementById('video3'), 2000);
            addPauseBeforeReplay(document.getElementById('video4'), 2000);
            addPauseBeforeReplay(document.getElementById('video5'), 2000);
            addPauseBeforeReplay(document.getElementById('video_shibuya'), 2000);
        });

        // Add this to your existing script
        document.addEventListener('DOMContentLoaded', function() {
            // Remove hints when user interacts with any mesh viewer
            const meshViewers = document.querySelectorAll('.mesh-viewer-container');
            meshViewers.forEach(viewer => {
                viewer.addEventListener('mousedown', function() {
                    const hint = this.querySelector('.interaction-hint');
                    if (hint) {
                        hint.style.display = 'none';
                    }
                });
            });
        });
    </script>
    </html>
</body>